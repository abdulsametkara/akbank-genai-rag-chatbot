# Gerekli kÃ¼tÃ¼phaneleri projemize dahil ediyoruz.
import streamlit as st
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate

# --- SAYFA AYARLARI ---
st.set_page_config(page_title="TÃ¼rkÃ§e Wikipedia RAG Chatbot", page_icon="ğŸ“š")
st.title("ğŸ“š TÃ¼rkÃ§e Wikipedia Destekli RAG Chatbot")
st.write(
    "Bu chatbot, sorduÄŸunuz sorulara TÃ¼rkÃ§e Wikipedia verilerini kullanarak cevap verir. "
    "Projenin GitHub reposuna [buradan](https://github.com/abdulsametkara/akbank-genai-rag-chatbot) ulaÅŸabilirsiniz."
)

# --- API ANAHTARI VE MODELLERÄ° YÃœKLEME ---

# .env dosyasÄ±nÄ± yÃ¼kleyerek iÃ§indeki deÄŸiÅŸkenleri ortam deÄŸiÅŸkeni olarak ayarla
load_dotenv()

# API anahtarÄ±nÄ± ortam deÄŸiÅŸkenlerinden gÃ¼venli bir ÅŸekilde alÄ±yoruz.
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    st.error("LÃ¼tfen GOOGLE_API_KEY'i ana dizindeki .env dosyasÄ±na ekleyin.")
    st.stop()

@st.cache_resource
def load_components():
    try:
        embeddings_model = HuggingFaceEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
        )
        vector_store = FAISS.load_local("faiss_index_wikipedia", embeddings_model, allow_dangerous_deserialization=True)
        return vector_store
    except Exception as e:
        st.error(f"HafÄ±za (VektÃ¶r VeritabanÄ±) yÃ¼klenirken bir hata oluÅŸtu: {e}")
        st.info("LÃ¼tfen 'faiss_index_wikipedia' klasÃ¶rÃ¼nÃ¼n bu projenin ana dizininde olduÄŸundan emin olun.")
        st.stop()

# Modelleri ve veritabanÄ±nÄ± yÃ¼kle
vector_store = load_components()


# --- RAG ZÄ°NCÄ°RÄ°NÄ° OLUÅTURMA ---
# (Bu kÄ±sÄ±mdan sonrasÄ± aynÄ± kalÄ±yor)
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", google_api_key=GOOGLE_API_KEY, temperature=0.4)
retriever = vector_store.as_retriever()
prompt_template_str = """
Sana verilen aÅŸaÄŸÄ±daki baÄŸlamÄ± (context) kullanarak soruya cevap ver.
CevabÄ±, sadece bu baÄŸlamdaki bilgilerden yola Ã§Ä±karak oluÅŸtur.
EÄŸer baÄŸlamda cevap yoksa, "Bu konuda hafÄ±zamda bir bilgi bulunmuyor." de.

BaÄŸlam (Context):
{context}

Soru: {input}

Cevap:
"""
prompt = ChatPromptTemplate.from_template(prompt_template_str)
retrieval_chain = create_retrieval_chain(
    retriever,
    create_stuff_documents_chain(llm, prompt)
)

# --- CHATBOT ARAYÃœZÃœ ---
if "messages" not in st.session_state:
    st.session_state.messages = []
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
if user_prompt := st.chat_input("Sorunuzu buraya yazabilirsiniz..."):
    st.session_state.messages.append({"role": "user", "content": user_prompt})
    with st.chat_message("user"):
        st.markdown(user_prompt)
    with st.chat_message("assistant"):
        with st.spinner("DÃ¼ÅŸÃ¼nÃ¼yorum..."):
            response = retrieval_chain.invoke({"input": user_prompt})
            answer = response["answer"]
            st.markdown(answer)
    st.session_state.messages.append({"role": "assistant", "content": answer})

