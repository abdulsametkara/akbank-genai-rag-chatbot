{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLxzIT7EkIk1",
        "outputId": "40518be3-9fdd-4c33-cd80-e3b200e4bebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> AdÄ±m 1.1: Gerekli kÃ¼tÃ¼phaneler tek seferde yÃ¼kleniyor...\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/ad/90/2660332eeb31303c13b653ea566a9918484b6e4d6b9d2d46879a33ab0622/pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.3/506.3 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "âœ… KÃ¼tÃ¼phane kurulumlarÄ± tamamlandÄ±!\n",
            "Not: Kurulum sÄ±rasÄ±nda hala bazÄ± uyarÄ±lar gÃ¶rebilirsin, bu Colab ortamÄ±nda normaldir.\n",
            "Bir sonraki API anahtarÄ± yÃ¼kleme adÄ±mÄ±na geÃ§ebilirsin.\n"
          ]
        }
      ],
      "source": [
        "# --- GÃœNCELLENMÄ°Å KURULUM KODU ---\n",
        "# TÃ¼m kÃ¼tÃ¼phaneleri tek bir komutla kurarak pip'in baÄŸÄ±mlÄ±lÄ±klarÄ± daha iyi Ã§Ã¶zmesine yardÄ±mcÄ± oluyoruz.\n",
        "# Bu yÃ¶ntem, versiyon Ã§akÄ±ÅŸmalarÄ±nÄ± en aza indirir.\n",
        "\n",
        "print(\">>> AdÄ±m 1.1: Gerekli kÃ¼tÃ¼phaneler tek seferde yÃ¼kleniyor...\")\n",
        "\n",
        "!pip install -qU \\\n",
        "    google-generativeai \\\n",
        "    langchain-google-genai \\\n",
        "    langchain \\\n",
        "    datasets \\\n",
        "    sentence-transformers \\\n",
        "    faiss-cpu \\\n",
        "    langchain_community\n",
        "\n",
        "print(\"\\nâœ… KÃ¼tÃ¼phane kurulumlarÄ± tamamlandÄ±!\")\n",
        "print(\"Not: Kurulum sÄ±rasÄ±nda hala bazÄ± uyarÄ±lar gÃ¶rebilirsin, bu Colab ortamÄ±nda normaldir.\")\n",
        "print(\"Bir sonraki API anahtarÄ± yÃ¼kleme adÄ±mÄ±na geÃ§ebilirsin.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bu hÃ¼cre, Colab'Ä±n gÃ¼venli 'Secrets' bÃ¶lÃ¼mÃ¼nden API anahtarÄ±mÄ±zÄ± alÄ±r ve\n",
        "# Google'Ä±n kÃ¼tÃ¼phanelerini bu anahtarla Ã§alÄ±ÅŸacak ÅŸekilde yapÄ±landÄ±rÄ±r.\n",
        "\n",
        "print(\">>> AdÄ±m 1.2: Google API anahtarÄ± yÃ¼kleniyor...\")\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata # Colab'Ä±n 'Secrets' bÃ¶lÃ¼mÃ¼ne eriÅŸmemizi saÄŸlayan araÃ§\n",
        "\n",
        "# 'try...except' bloÄŸu, olasÄ± bir hatayÄ± yakalamamÄ±zÄ± saÄŸlar.\n",
        "# EÄŸer anahtar doÄŸru yÃ¼klenirse 'try' iÃ§indeki kod Ã§alÄ±ÅŸÄ±r.\n",
        "# Bir sorun olursa 'except' iÃ§indeki hata mesajÄ± gÃ¶sterilir.\n",
        "try:\n",
        "    # 'userdata.get()' fonksiyonu ile 'GOOGLE_API_KEY' isimli gizli anahtarÄ±mÄ±zÄ± Ã§aÄŸÄ±rÄ±yoruz.\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "    # 'genai.configure()' fonksiyonu ile Google kÃ¼tÃ¼phanelerine anahtarÄ±mÄ±zÄ± tanÄ±tÄ±yoruz.\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "    print(\"âœ… Google API anahtarÄ± baÅŸarÄ±yla yÃ¼klendi ve yapÄ±landÄ±rÄ±ldÄ±.\")\n",
        "    print(\"ArtÄ±k projemizin bir sonraki adÄ±mÄ±na geÃ§meye hazÄ±rÄ±z!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"ğŸš¨ HATA: API anahtarÄ± yÃ¼klenemedi!\")\n",
        "    print(\"LÃ¼tfen Colab'Ä±n sol menÃ¼sÃ¼ndeki 'Secrets' (anahtar simgesi) bÃ¶lÃ¼mÃ¼ne\")\n",
        "    print(\"API anahtarÄ±nÄ±zÄ± 'GOOGLE_API_KEY' adÄ±yla doÄŸru bir ÅŸekilde eklediÄŸinizden emin olun.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uf5-Nc_lOJU",
        "outputId": "58dbe965-1892-4b6c-9d57-55bdd91ae21a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> AdÄ±m 1.2: Google API anahtarÄ± yÃ¼kleniyor...\n",
            "âœ… Google API anahtarÄ± baÅŸarÄ±yla yÃ¼klendi ve yapÄ±landÄ±rÄ±ldÄ±.\n",
            "ArtÄ±k projemizin bir sonraki adÄ±mÄ±na geÃ§meye hazÄ±rÄ±z!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- AdÄ±m 2 (GeniÅŸletilmiÅŸ Alt KÃ¼me Versiyonu) ---\n",
        "\n",
        "print(\">>> AdÄ±m 2: TÃ¼rkÃ§e Wikipedia veri seti yÃ¼kleniyor...\")\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "try:\n",
        "    dataset = load_dataset(\"wikimedia/wikipedia\", \"20231101.tr\", split='train')\n",
        "    print(f\"\\nâœ… Orijinal veri setinde toplam {len(dataset)} adet makale bulundu.\")\n",
        "\n",
        "    # --- DEÄÄ°ÅÄ°KLÄ°K BURADA ---\n",
        "    # KÄ±sÄ±tlamayÄ± 1000'den 20,000 makaleye Ã§Ä±karÄ±yoruz.\n",
        "    subset_dataset = dataset.select(range(20000))\n",
        "\n",
        "    print(f\"\\nâœ… GeliÅŸtirme iÃ§in {len(subset_dataset)} makalelik bir alt kÃ¼me oluÅŸturuldu.\")\n",
        "    print(\"ArtÄ±k bu alt kÃ¼me ile Ã§alÄ±ÅŸacaÄŸÄ±z.\")\n",
        "\n",
        "    print(\"\\n--- Ã–rnek Veri ---\")\n",
        "    print(\"Ä°lk makalenin baÅŸlÄ±ÄŸÄ±:\", subset_dataset[0]['title'])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ğŸš¨ HATA: Veri seti yÃ¼klenirken bir sorun oluÅŸtu!\\n{e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RALIp_ybnqL3",
        "outputId": "f27774b2-68a0-4c92-80e3-b0ef534138e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> AdÄ±m 2: TÃ¼rkÃ§e Wikipedia veri seti yÃ¼kleniyor...\n",
            "\n",
            "âœ… Orijinal veri setinde toplam 534988 adet makale bulundu.\n",
            "\n",
            "âœ… GeliÅŸtirme iÃ§in 20000 makalelik bir alt kÃ¼me oluÅŸturuldu.\n",
            "ArtÄ±k bu alt kÃ¼me ile Ã§alÄ±ÅŸacaÄŸÄ±z.\n",
            "\n",
            "--- Ã–rnek Veri ---\n",
            "Ä°lk makalenin baÅŸlÄ±ÄŸÄ±: Cengiz Han\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bu hÃ¼cre, bir Ã¶nceki adÄ±mda yÃ¼klediÄŸimiz 1000 makaleyi\n",
        "# daha kÃ¼Ã§Ã¼k ve yÃ¶netilebilir metin parÃ§alarÄ±na (\"chunk\") bÃ¶ler.\n",
        "\n",
        "print(\">>> AdÄ±m 3: Metinleri daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rma iÅŸlemi baÅŸlÄ±yor...\")\n",
        "\n",
        "# LangChain'in metin bÃ¶lme aracÄ±nÄ± projemize dahil ediyoruz.\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "try:\n",
        "    # Metinleri LangChain'in anlayacaÄŸÄ± Ã¶zel bir \"Document\" formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz.\n",
        "    # Her makalenin 'text' iÃ§eriÄŸini alÄ±p bir liste oluÅŸturuyoruz.\n",
        "    docs_list = [article['text'] for article in subset_dataset]\n",
        "\n",
        "    # Metin bÃ¶lÃ¼cÃ¼mÃ¼zÃ¼ yapÄ±landÄ±rÄ±yoruz:\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,      # Her bir parÃ§anÄ±n maksimum karakter sayÄ±sÄ±.\n",
        "        chunk_overlap=150,    # ParÃ§alar arasÄ± anlamsal bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ korumak iÃ§in ortak karakter sayÄ±sÄ±.\n",
        "        length_function=len,  # Karakter sayÄ±sÄ±nÄ± nasÄ±l Ã¶lÃ§eceÄŸimizi belirtiyoruz (standart Python len fonksiyonu).\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "\n",
        "    # BÃ¶lÃ¼cÃ¼yÃ¼ kullanarak metin listemizi parÃ§alara ayÄ±rÄ±yoruz.\n",
        "    # Bu iÅŸlem sonucunda elimizde bir \"Document\" nesneleri listesi olacak.\n",
        "    chunks = text_splitter.create_documents(docs_list)\n",
        "\n",
        "    print(\"\\nâœ… Metin parÃ§alama iÅŸlemi baÅŸarÄ±yla tamamlandÄ±.\")\n",
        "    print(f\"BaÅŸlangÄ±Ã§ta {len(docs_list)} adet tam makalemiz vardÄ±.\")\n",
        "    print(f\"ParÃ§alama sonrasÄ± toplam {len(chunks)} adet metin parÃ§asÄ± (chunk) oluÅŸturuldu.\")\n",
        "\n",
        "    # OluÅŸturduÄŸumuz parÃ§alardan birine gÃ¶z atalÄ±m.\n",
        "    print(\"\\n--- Ã–rnek ParÃ§a (Chunk) ---\")\n",
        "    # chunks listesindeki 10. parÃ§anÄ±n iÃ§eriÄŸini (page_content) yazdÄ±ralÄ±m.\n",
        "    print(chunks[10].page_content)\n",
        "    print(\"-----------------------------\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"ğŸš¨ HATA: Metinler parÃ§alanÄ±rken bir sorun oluÅŸtu!\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmFa0tjHoik4",
        "outputId": "962b77b8-ce16-4307-f5e5-86dfa6914766"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> AdÄ±m 3: Metinleri daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rma iÅŸlemi baÅŸlÄ±yor...\n",
            "\n",
            "âœ… Metin parÃ§alama iÅŸlemi baÅŸarÄ±yla tamamlandÄ±.\n",
            "BaÅŸlangÄ±Ã§ta 20000 adet tam makalemiz vardÄ±.\n",
            "ParÃ§alama sonrasÄ± toplam 144739 adet metin parÃ§asÄ± (chunk) oluÅŸturuldu.\n",
            "\n",
            "--- Ã–rnek ParÃ§a (Chunk) ---\n",
            "Kabul Han ve onun halefi Ambakay Han zamanÄ±nda MoÄŸollar, Ã‡in'deki Jin Ä°mparatorluÄŸu ile mÃ¼cadele edecek kadar kuvvetlenseler de Tatarlar, Ã‡inlileri hoÅŸnut etmek iÃ§in Ambakayâ€™Ä± Ã‡inâ€™e teslim ettiler. Ambakay hiÃ§ alÄ±ÅŸÄ±lmadÄ±k bir ÅŸekilde, â€œtahta eÅŸek ÅŸekliâ€ denen bir duruma sokularak Ã§armÄ±ha gerilip infaz edildi. Cengiz Hanâ€™Ä±n bÃ¼yÃ¼k amcasÄ± Kutua, bu hakarete Ã‡in Ã¼zerine ve Tatarlara bir dizi saldÄ±rÄ± dÃ¼zenleyerek cevap verdi ve bu akÄ±nlar sonunda â€œMoÄŸol HerkÃ¼lÃ¼â€ unvanÄ±nÄ± kazandÄ±. Fakat, 1160 yÄ±lÄ±nda, detaylarÄ± bilinmeyen bir dizi olay sonunda, Kuzey Ã‡inâ€™in hakimi Jin HanedanÄ±, MoÄŸollarÄ± hezimete uÄŸrattÄ±. MoÄŸollar bir sÃ¼re karmaÅŸa iÃ§inde daÄŸÄ±ldÄ±lar. Sefalet iÃ§inde yÃ¼zen bu karmaÅŸÄ±k hÃ¢ldeki MoÄŸollarâ€™Ä±n iÃ§erisindeki Ã¶nemsiz liderlerden biri olan Kabul Han'Ä±n torunu YesÃ¼gey BahadÄ±r, ittifaklar kurarak MoÄŸollarÄ± gÃ¼Ã§lendirmeye Ã§alÄ±ÅŸtÄ±. MoÄŸollarÄ±n batÄ± komÅŸularÄ±ndan biri olan TÃ¼rk boylarÄ±ndan Keraitler idi. Keraitler 200 yÄ±ldan beri Nasturi Hristiyanâ€™dÄ±. Hristiyan Keraitlerin o zamanki lideri\n",
            "-----------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bu hÃ¼cre, 10,685 adet metin parÃ§asÄ±nÄ±n TAMAMINI anlamsal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve\n",
        "# bu vektÃ¶rleri hÄ±zlÄ± arama iÃ§in bir veritabanÄ±na kaydeder.\n",
        "\n",
        "print(\">>> AdÄ±m 4 (Tam SÃ¼rÃ¼m): VektÃ¶r veritabanÄ± oluÅŸturuluyor...\")\n",
        "print(f\"âš ï¸ UYARI: Toplam {len(chunks)} adet metin parÃ§asÄ± iÅŸlenecek. Bu iÅŸlem Ã§ok uzun sÃ¼rebilir!\")\n",
        "\n",
        "# Gerekli araÃ§larÄ± LangChain'den Ã§aÄŸÄ±rÄ±yoruz.\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "try:\n",
        "    # \"Anlam TercÃ¼manÄ±mÄ±zÄ±\" (Embedding Model) yÃ¼klÃ¼yoruz.\n",
        "    # Model daha Ã¶nce indirildiÄŸi iÃ§in bu adÄ±m hÄ±zlÄ± olacaktÄ±r.\n",
        "    model_name = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "    embeddings_model = HuggingFaceEmbeddings(model_name=model_name)\n",
        "    print(\"\\nâœ… Embedding modeli baÅŸarÄ±yla yÃ¼klendi.\")\n",
        "\n",
        "\n",
        "    # --- ANA DEÄÄ°ÅÄ°KLÄ°K BURADA ---\n",
        "    # ArtÄ±k verinin kÃ¼Ã§Ã¼k bir kÄ±smÄ±nÄ± deÄŸil, 'chunks' listesinin tamamÄ±nÄ± kullanÄ±yoruz.\n",
        "    print(\"Metin parÃ§alarÄ± vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor ve veritabanÄ±na ekleniyor...\")\n",
        "    vector_store = FAISS.from_documents(chunks, embeddings_model) # 'small_chunks' yerine 'chunks' kullanÄ±lÄ±yor.\n",
        "\n",
        "    print(\"\\nâœ… VektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "    print(f\"VeritabanÄ±nda toplam {vector_store.index.ntotal} adet vektÃ¶r (metin parÃ§asÄ±) bulunmaktadÄ±r.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"ğŸš¨ HATA: VektÃ¶r veritabanÄ± oluÅŸturulurken bir sorun oluÅŸtu!\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK5mxd7n8q5A",
        "outputId": "63e0937a-97cf-481e-d26f-e0b9dda2e4ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> AdÄ±m 4 (Tam SÃ¼rÃ¼m): VektÃ¶r veritabanÄ± oluÅŸturuluyor...\n",
            "âš ï¸ UYARI: Toplam 144739 adet metin parÃ§asÄ± iÅŸlenecek. Bu iÅŸlem Ã§ok uzun sÃ¼rebilir!\n",
            "\n",
            "âœ… Embedding modeli baÅŸarÄ±yla yÃ¼klendi.\n",
            "Metin parÃ§alarÄ± vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor ve veritabanÄ±na ekleniyor...\n",
            "\n",
            "âœ… VektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu!\n",
            "VeritabanÄ±nda toplam 144739 adet vektÃ¶r (metin parÃ§asÄ±) bulunmaktadÄ±r.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bu hÃ¼cre, RAG mimarisinin tÃ¼m parÃ§alarÄ±nÄ± birleÅŸtirir ve\n",
        "# kullanÄ±cÄ±nÄ±n sorduÄŸu bir soruya, vektÃ¶r veritabanÄ±ndaki bilgileri\n",
        "# kullanarak cevap Ã¼retir.\n",
        "\n",
        "print(\">>> AdÄ±m 5 (DÃ¼zeltilmiÅŸ Versiyon): RAG Zinciri oluÅŸturuluyor...\")\n",
        "\n",
        "# Gerekli araÃ§larÄ± LangChain ve Google kÃ¼tÃ¼phanelerinden Ã§aÄŸÄ±rÄ±yoruz.\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "try:\n",
        "    # 1. BEYNÄ° (LLM) TANIMLAMA\n",
        "\n",
        "    # --- ANA DEÄÄ°ÅÄ°KLÄ°K BURADA ---\n",
        "    # Gemini modelini Ã§aÄŸÄ±rÄ±rken, kimlik doÄŸrulama hatasÄ±nÄ± Ã¶nlemek iÃ§in\n",
        "    # API anahtarÄ±mÄ±zÄ± 'google_api_key' parametresi ile doÄŸrudan belirtiyoruz.\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",\n",
        "                                 google_api_key=GOOGLE_API_KEY,\n",
        "                                 temperature=0.3)\n",
        "\n",
        "    # 2. HAFIZAYI (RETRIEVER) TANIMLAMA\n",
        "    retriever = vector_store.as_retriever()\n",
        "\n",
        "    # 3. BEYNE TALÄ°MAT VERME (PROMPT ÅABLONU OLUÅTURMA)\n",
        "    prompt_template = \"\"\"\n",
        "    Sana verilen aÅŸaÄŸÄ±daki baÄŸlamÄ± (context) kullanarak soruya cevap ver.\n",
        "    CevabÄ±, sadece bu baÄŸlamdaki bilgilerden yola Ã§Ä±karak oluÅŸtur.\n",
        "    EÄŸer baÄŸlamda cevap yoksa, \"Bu konuda bilgim yok.\" de.\n",
        "\n",
        "    BaÄŸlam (Context):\n",
        "    {context}\n",
        "\n",
        "    Soru: {input}\n",
        "\n",
        "    Cevap:\n",
        "    \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    # 4. ZÄ°NCÄ°RÄ° OLUÅTURMA\n",
        "    combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
        "    retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
        "\n",
        "    print(\"\\nâœ… RAG Zinciri baÅŸarÄ±yla oluÅŸturuldu!\")\n",
        "\n",
        "    # 5. Ä°LK SORUMUZU SORMA\n",
        "    test_sorusu = \"tÃ¼rkiye nin baÅŸkenti neresi?\"\n",
        "    print(f\"\\nâ“ Soru soruluyor: '{test_sorusu}'\")\n",
        "\n",
        "    response = retrieval_chain.invoke({\"input\": test_sorusu})\n",
        "\n",
        "    print(\"\\nğŸ¤– Gelen Cevap:\")\n",
        "    print(response[\"answer\"])\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"ğŸš¨ HATA: RAG zinciri Ã§alÄ±ÅŸtÄ±rÄ±lÄ±rken bir sorun oluÅŸtu!\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A-QFa1w4-0X",
        "outputId": "945f5218-f5aa-46d1-8c5f-5de45f95e411"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> AdÄ±m 5 (DÃ¼zeltilmiÅŸ Versiyon): RAG Zinciri oluÅŸturuluyor...\n",
            "\n",
            "âœ… RAG Zinciri baÅŸarÄ±yla oluÅŸturuldu!\n",
            "\n",
            "â“ Soru soruluyor: 'tÃ¼rkiye nin baÅŸkenti neresi?'\n",
            "\n",
            "ğŸ¤– Gelen Cevap:\n",
            "Ankara, TÃ¼rkiye'nin baÅŸkentidir.\n"
          ]
        }
      ]
    }
  ]
}